{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_quality_bspc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/absbin/Image-quality-evaluation/blob/master/image_quality_bspc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FpigC2ilvNxS"
      },
      "source": [
        "Loading preliminaries, models, and required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7e30bf6c-09e5-451e-84e3-c4ced75c1e64",
        "id": "X5sZQpgyvaZL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import json\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import glob\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import zipfile\n",
        "from termcolor import colored\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.models import model_from_json, load_model\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')\n",
        "#!pip install matplotlib\n",
        "base_path='/content/drive/My Drive/models_bspc' \n",
        "%cd '/content/drive/My Drive/models_bspc' \n",
        "!pwd\n",
        "import feature2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/models_bspc\n",
            "/content/drive/My Drive/models_bspc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ddd3gWn6Lzk",
        "colab_type": "text"
      },
      "source": [
        "Feature extraction & Image quality evalauation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b6311e8f-d691-499e-eb62-a3d9d54d69f2",
        "id": "BH0v9bFE9XWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "\n",
        "x_data_demo,y_data,img_address=feature2.feature_ext(base_path )\n",
        "\n",
        "pkl_svm_filename = 'pickle_svm_model.pkl'\n",
        "with open(pkl_svm_filename, 'rb') as file:\n",
        "    pickle_model = pickle.load(file)\n",
        "y_pred_demo=pickle_model.predict(x_data_demo)\n",
        "if y_pred_demo==1:\n",
        "  print(colored('\\n\\n\\n *****WCE frame is informative*****','green'))\n",
        "else:\n",
        "  print(colored('\\n\\n\\n *****WCE frame is non-informative*****','red'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '/content/drive/My Drive/models_bspc/Naser Mohammadi 2017_03_15 ( 00.07.06 )_2.jpg')\n",
            "\u001b[32m\n",
            "\n",
            "\n",
            " *****WCE frame is informative*****\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}